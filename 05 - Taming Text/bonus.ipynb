{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communication graph\n",
    "\n",
    "BONUS: Build the communication graph (unweighted and undirected) among the different email senders and recipients using the NetworkX library. Find communities in this graph with community.best_partition(G) method from the community detection module. Print the most frequent 20 words used by the email authors of each community. Do these word lists look similar to what you've produced at step 3 with LDA? Can you identify clear discussion topics for each community? Discuss briefly the obtained results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd                                     \n",
    "import numpy as np                                      \n",
    "\n",
    "import networkx as nx\n",
    "import community\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DocNumber</th>\n",
       "      <th>MetadataSubject</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>MetadataFrom</th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataDateSent</th>\n",
       "      <th>MetadataDateReleased</th>\n",
       "      <th>MetadataPdfLink</th>\n",
       "      <th>MetadataCaseNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>ExtractedTo</th>\n",
       "      <th>ExtractedFrom</th>\n",
       "      <th>ExtractedCc</th>\n",
       "      <th>ExtractedDateSent</th>\n",
       "      <th>ExtractedCaseNumber</th>\n",
       "      <th>ExtractedDocNumber</th>\n",
       "      <th>ExtractedDateReleased</th>\n",
       "      <th>ExtractedReleaseInPartOrFull</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>RawText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>WOW</td>\n",
       "      <td>H</td>\n",
       "      <td>Sullivan, Jacob J</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sullivan, Jacob J &lt;Sullivan11@state.gov&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wednesday, September 12, 2012 10:16 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739545</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN FULL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-03T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739546</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>CHRIS STEVENS</td>\n",
       "      <td>;H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>B6</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>Wednesday, September 12, 2012 11:52 AM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739547</td>\n",
       "      <td>05/14/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>Thx</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>CAIRO CONDEMNATION - FINAL</td>\n",
       "      <td>H</td>\n",
       "      <td>Mills, Cheryl D</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2012-09-12T04:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mills, Cheryl D &lt;MillsCD@state.gov&gt;</td>\n",
       "      <td>Mitchell, Andrew B</td>\n",
       "      <td>Wednesday, September 12,2012 12:44 PM</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739550</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNCLASSIFIED\\nU.S. Department of State\\nCase N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...</td>\n",
       "      <td>Abedin, Huma</td>\n",
       "      <td>H</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2011-03-11T05:00:00+00:00</td>\n",
       "      <td>2015-05-22T04:00:00+00:00</td>\n",
       "      <td>DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F-2015-04841</td>\n",
       "      <td>C05739554</td>\n",
       "      <td>05/13/2015</td>\n",
       "      <td>RELEASE IN PART</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "      <td>B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  DocNumber                                    MetadataSubject  \\\n",
       "0   1  C05739545                                                WOW   \n",
       "1   2  C05739546  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "2   3  C05739547                                      CHRIS STEVENS   \n",
       "3   4  C05739550                         CAIRO CONDEMNATION - FINAL   \n",
       "4   5  C05739554  H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...   \n",
       "\n",
       "     MetadataTo       MetadataFrom  SenderPersonId           MetadataDateSent  \\\n",
       "0             H  Sullivan, Jacob J            87.0  2012-09-12T04:00:00+00:00   \n",
       "1             H                NaN             NaN  2011-03-03T05:00:00+00:00   \n",
       "2            ;H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "3             H    Mills, Cheryl D            32.0  2012-09-12T04:00:00+00:00   \n",
       "4  Abedin, Huma                  H            80.0  2011-03-11T05:00:00+00:00   \n",
       "\n",
       "        MetadataDateReleased  \\\n",
       "0  2015-05-22T04:00:00+00:00   \n",
       "1  2015-05-22T04:00:00+00:00   \n",
       "2  2015-05-22T04:00:00+00:00   \n",
       "3  2015-05-22T04:00:00+00:00   \n",
       "4  2015-05-22T04:00:00+00:00   \n",
       "\n",
       "                                     MetadataPdfLink MetadataCaseNumber  \\\n",
       "0  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739545...       F-2015-04841   \n",
       "1  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739546...       F-2015-04841   \n",
       "2  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739547...       F-2015-04841   \n",
       "3  DOCUMENTS/HRC_Email_1_296/HRCH2/DOC_0C05739550...       F-2015-04841   \n",
       "4  DOCUMENTS/HRC_Email_1_296/HRCH1/DOC_0C05739554...       F-2015-04841   \n",
       "\n",
       "                         ...                         ExtractedTo  \\\n",
       "0                        ...                                 NaN   \n",
       "1                        ...                                 NaN   \n",
       "2                        ...                                  B6   \n",
       "3                        ...                                 NaN   \n",
       "4                        ...                                 NaN   \n",
       "\n",
       "                              ExtractedFrom         ExtractedCc  \\\n",
       "0  Sullivan, Jacob J <Sullivan11@state.gov>                 NaN   \n",
       "1                                       NaN                 NaN   \n",
       "2       Mills, Cheryl D <MillsCD@state.gov>        Abedin, Huma   \n",
       "3       Mills, Cheryl D <MillsCD@state.gov>  Mitchell, Andrew B   \n",
       "4                                       NaN                 NaN   \n",
       "\n",
       "                        ExtractedDateSent ExtractedCaseNumber  \\\n",
       "0  Wednesday, September 12, 2012 10:16 AM        F-2015-04841   \n",
       "1                                     NaN        F-2015-04841   \n",
       "2  Wednesday, September 12, 2012 11:52 AM        F-2015-04841   \n",
       "3   Wednesday, September 12,2012 12:44 PM        F-2015-04841   \n",
       "4                                     NaN        F-2015-04841   \n",
       "\n",
       "  ExtractedDocNumber ExtractedDateReleased ExtractedReleaseInPartOrFull  \\\n",
       "0          C05739545            05/13/2015              RELEASE IN FULL   \n",
       "1          C05739546            05/13/2015              RELEASE IN PART   \n",
       "2          C05739547            05/14/2015              RELEASE IN PART   \n",
       "3          C05739550            05/13/2015              RELEASE IN PART   \n",
       "4          C05739554            05/13/2015              RELEASE IN PART   \n",
       "\n",
       "                                   ExtractedBodyText  \\\n",
       "0                                                NaN   \n",
       "1  B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...   \n",
       "2                                                Thx   \n",
       "3                                                NaN   \n",
       "4  H <hrod17@clintonemail.com>\\nFriday, March 11,...   \n",
       "\n",
       "                                             RawText  \n",
       "0  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "1  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "2  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "3  UNCLASSIFIED\\nU.S. Department of State\\nCase N...  \n",
       "4  B6\\nUNCLASSIFIED\\nU.S. Department of State\\nCa...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = pd.read_csv(\"hillary-clinton-emails/Emails.csv\")\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning of the data\n",
    "The ExtractedBodyText is used for this analyse of the content of the emails. While the RawText contains more informations and some email bodies are missing from the ExtractedBodyText, it has the advantage of being cleaned from all the headers. The MetadataTo field is used as the way to determine the recipient since it provides a much more consistent recipient than ExtractedTo, altough it loses the information about eventual multiple recipients for the same email.\n",
    "The recipient and sender data is cleaned and converted to lowercase to ease the use of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SenderPersonId</th>\n",
       "      <th>MetadataTo</th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.0</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>;h</td>\n",
       "      <td>Thx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.0</td>\n",
       "      <td>abedin, huma</td>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80.0</td>\n",
       "      <td>russorv@state.gov</td>\n",
       "      <td>Pis print.\\n-â€¢-...-^\\nH &lt; hrod17@clintonernail...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SenderPersonId         MetadataTo  \\\n",
       "0            87.0                  h   \n",
       "2            32.0                 ;h   \n",
       "3            32.0                  h   \n",
       "4            80.0       abedin, huma   \n",
       "5            80.0  russorv@state.gov   \n",
       "\n",
       "                                   ExtractedBodyText  \n",
       "0                                                NaN  \n",
       "2                                                Thx  \n",
       "3                                                NaN  \n",
       "4  H <hrod17@clintonemail.com>\\nFriday, March 11,...  \n",
       "5  Pis print.\\n-â€¢-...-^\\nH < hrod17@clintonernail...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = emails[['SenderPersonId', 'MetadataTo', 'ExtractedBodyText']]\n",
    "edges = edges.dropna(subset=['SenderPersonId', 'MetadataTo'])\n",
    "edges['MetadataTo'] = edges['MetadataTo'].apply(lambda x: x.lower())\n",
    "edges.shape\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval of the name of the senders and recipients\n",
    "The names of the senders and recipients corresponding to the MetadataIn and SenderPersonId are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge 1: (7392, 3)\n",
      "merge 2: (7392, 3)\n",
      "merge 3: (7392, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExtractedBodyText</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FYI</td>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fyi\\nB6\\nâ€” â€”</td>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fyi</td>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is nice.</td>\n",
       "      <td>Jake Sullivan</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ExtractedBodyText         Sender        Recipient\n",
       "0               NaN  Jake Sullivan  Hillary Clinton\n",
       "1               FYI  Jake Sullivan  Hillary Clinton\n",
       "2      Fyi\\nB6\\nâ€” â€”  Jake Sullivan  Hillary Clinton\n",
       "3               Fyi  Jake Sullivan  Hillary Clinton\n",
       "4     This is nice.  Jake Sullivan  Hillary Clinton"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliases = pd.read_csv(\"hillary-clinton-emails/Aliases.csv\")\n",
    "persons = pd.read_csv(\"hillary-clinton-emails/Persons.csv\")\n",
    "edgesId = pd.merge(edges, aliases[['Alias', 'PersonId']], how='inner', left_on='MetadataTo', right_on='Alias')\n",
    "edgesId = edgesId.drop(['MetadataTo','Alias'], axis=1)\n",
    "print(\"merge 1:\", edgesId.shape)\n",
    "edgesId = pd.merge(edgesId, persons, how='inner', left_on='SenderPersonId', right_on='Id')\n",
    "edgesId = edgesId.drop(['SenderPersonId','Id'], axis=1)\n",
    "edgesId.columns = ['ExtractedBodyText', 'PersonId', 'Sender']\n",
    "print(\"merge 2:\", edgesId.shape)\n",
    "edgesId = pd.merge(edgesId, persons, how='inner', left_on='PersonId', right_on='Id')\n",
    "edgesId = edgesId.drop(['PersonId','Id'], axis=1)\n",
    "edgesId.columns = ['ExtractedBodyText', 'Sender', 'Recipient']\n",
    "print(\"merge 3:\", edgesId.shape)\n",
    "edgesId.head()\n",
    "edgesId.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the communication graph\n",
    "To create a communication graph, the senders and recipients of each email are defined as edges and all the people present as senders or recipients become a node in the graph. The community.best_partition() method is used to cluster the people into communities. The different communities are represented by different node colors in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'community' has no attribute 'best_partition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7f80ac1f89bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#first compute the best partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#drawing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'community' has no attribute 'best_partition'"
     ]
    }
   ],
   "source": [
    "G=nx.from_pandas_dataframe(edgesId[['Sender', 'Recipient']], 'Sender', 'Recipient')\n",
    "\n",
    "#first compute the best partition\n",
    "partition = community.best_partition(G)\n",
    "\n",
    "#drawing\n",
    "size = float(len(set(partition.values())))\n",
    "pos = nx.spring_layout(G)\n",
    "count = 0.\n",
    "for com in set(partition.values()) :\n",
    "    count = count + 1.\n",
    "    list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "    nx.draw_networkx_nodes(G, pos, list_nodes, node_size = 20,\n",
    "                                node_color = str(count / size))\n",
    "\n",
    "nx.draw_networkx_edges(G,pos, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The community number corresponding to each person is retrieved from the partition created by the community.best_partition() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-24c0777b0f60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpartition_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpartition_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Community_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpartition_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partition' is not defined"
     ]
    }
   ],
   "source": [
    "partition_frame = pd.Series(partition).reset_index()\n",
    "partition_frame.columns = ['Name', 'Community_number']\n",
    "partition_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition data processing\n",
    "Now that the graph partition data have been determined, the emails with an empty body can be removed since they don't help for the topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edgesId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cbe529326484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medges_community\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medgesId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0medges_community\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0medges_community\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0medges_community\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ExtractedBodyText'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges_community\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ExtractedBodyText'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edgesId' is not defined"
     ]
    }
   ],
   "source": [
    "edges_community = pd.merge(edgesId, partition_frame, how='inner', left_on='Sender', right_on='Name')\n",
    "edges_community = edges_community.drop(['Name'], axis=1)\n",
    "edges_community = edges_community.dropna()\n",
    "edges_community['ExtractedBodyText'] = edges_community['ExtractedBodyText'].apply(lambda x: x.lower())\n",
    "print(edges_community.shape)\n",
    "edges_community.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen on the following table, the senders have been clustered into 8 different communities but a lot of them consist of only one or two persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges_community' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e3998af97e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommunity_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medges_community\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Community_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcommunity_groups_groupby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunity_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Community_number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcommunity_groups_groupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edges_community' is not defined"
     ]
    }
   ],
   "source": [
    "community_groups = edges_community[['Sender', 'Community_number']].drop_duplicates()\n",
    "community_groups_groupby = community_groups.groupby('Community_number')['Sender'].apply(lambda x: \"%s\" % ', '.join(x))\n",
    "community_groups_groupby.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usual stopwords are used from the nltk.corpus library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'corpora/stopwords' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/jeremie/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/Users/jeremie/anaconda/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremie/anaconda/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/stopwords.zip/stopwords/' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - '/Users/jeremie/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b4bd32aec3ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopwordlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstopwordlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"â€”\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstopwordlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"â€¢\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstopwordlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstopwordlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremie/anaconda/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremie/anaconda/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremie/anaconda/lib/python3.5/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jeremie/anaconda/lib/python3.5/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'corpora/stopwords' not found.  Please use the NLTK\n  Downloader to obtain the resource:  >>> nltk.download()\n  Searched in:\n    - '/Users/jeremie/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "stopwordlist = stopwords.words('english')\n",
    "stopwordlist.append(\"â€”\")\n",
    "stopwordlist.append(\"â€¢\")\n",
    "stopwordlist.append(\"--\")\n",
    "stopwordlist.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function counts the number of occurences of each word from a DataFrame and returns a dictionnary word -> occurency. The second function takes a word -> occurency dictionnany and removes the key-value pairs present in the stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countWords(emails_body):\n",
    "    emails_body.to_csv(\"hillary-clinton-emails/emails_body_clean.csv\")\n",
    "    with open(\"hillary-clinton-emails/emails_body_clean.csv\") as data:\n",
    "        wordcount = Counter(data.read().split())      \n",
    "    return wordcount\n",
    "\n",
    "def removeStopwords(wordcount):\n",
    "    for stopword in stopwordlist:\n",
    "        if wordcount[stopword] > 0:\n",
    "            wordcount.pop(stopword, None)       \n",
    "    return wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "The calculation of the word occurencies are performed on each community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community number: 0 \n",
      "\n",
      "        Number of appearances\n",
      "would                    412\n",
      "state                    367\n",
      "w                        314\n",
      "get                      278\n",
      "u.s.                     271\n",
      "call                     262\n",
      "also                     249\n",
      "see                      248\n",
      "know                     244\n",
      "new                      242\n",
      "pm                       235\n",
      "us                       224\n",
      "2010                     208\n",
      "one                      203\n",
      "like                     195\n",
      "women                    190\n",
      "could                    187\n",
      "i'm                      185\n",
      "need                     183\n",
      "work                     182 \n",
      "\n",
      "\n",
      "Community number: 2 \n",
      "\n",
      "              Number of appearances\n",
      "pm                            1728\n",
      "state                          999\n",
      "would                          978\n",
      "office                         855\n",
      "new                            717\n",
      "president                      676\n",
      "one                            668\n",
      "obama                          641\n",
      "secretary's                    634\n",
      "house                          602\n",
      "said                           590\n",
      "u.s.                           583\n",
      "meeting                        553\n",
      "department                     545\n",
      "also                           537\n",
      "call                           517\n",
      "time                           501\n",
      "2010                           492\n",
      "2009                           492\n",
      "american                       460 \n",
      "\n",
      "\n",
      "Community number: 3 \n",
      "\n",
      "              Number of appearances\n",
      "health                          25\n",
      "obama                           21\n",
      "care                            17\n",
      "insurance                       15\n",
      "women                           14\n",
      "could                           13\n",
      "democratic                      11\n",
      "public                          11\n",
      "would                           11\n",
      "mandate                         10\n",
      "people                           9\n",
      "support                          9\n",
      "obama's                          8\n",
      "letter                           8\n",
      "republicans                      8\n",
      "make                             8\n",
      "president                        7\n",
      "new                              7\n",
      "way                              6\n",
      "democrats                        6 \n",
      "\n",
      "\n",
      "Community number: 4 \n",
      "\n",
      "              Number of appearances\n",
      "un                              54\n",
      "people                          44\n",
      "haitian                         40\n",
      "settlements                     36\n",
      "could                           28\n",
      "work                            24\n",
      "would                           24\n",
      "au                              22\n",
      "settlement                      20\n",
      "one                             20\n",
      "port                            20\n",
      "government                      20\n",
      "ensure                          18\n",
      "ingo                            18\n",
      "(e.g.,                          18\n",
      "plan                            18\n",
      "including                       18\n",
      "security                        18\n",
      "needs                           18\n",
      "though                          17 \n",
      "\n",
      "\n",
      "Community number: 6 \n",
      "\n",
      "            Number of appearances\n",
      "last                           3\n",
      "back                           3\n",
      "morning.                       3\n",
      "ops                            3\n",
      "wanted                         3\n",
      "call                           3\n",
      "yesterday                      2\n",
      "come                           2\n",
      "aid?                           2\n",
      "asked                          2\n",
      "budget                         2\n",
      "pm                             2\n",
      "dc                             2\n",
      "today.                         2\n",
      "part                           2\n",
      "get                            2\n",
      "h                              2\n",
      "hours                          2\n",
      "afternoon                      2\n",
      "reached                        2 \n",
      "\n",
      "\n",
      "Community number: 7 \n",
      "\n",
      "             Number of appearances\n",
      "mr.                            33\n",
      "said                           27\n",
      "women                          21\n",
      "new                            19\n",
      "richards                       19\n",
      "one                            19\n",
      "first                          17\n",
      "state                          16\n",
      "people                         16\n",
      "fisa                           13\n",
      "pm                             13\n",
      "would                          12\n",
      "city                           12\n",
      "get                            12\n",
      "many                           12\n",
      "ms.                            11\n",
      "house                          11\n",
      "office                         11\n",
      "2010                           10\n",
      "foundation                     10 \n",
      "\n",
      "\n",
      "Community number: 8 \n",
      "\n",
      "          Number of appearances\n",
      ">                           34\n",
      "draft                       27\n",
      "h                           21\n",
      "get                         19\n",
      "wrote:                      19\n",
      "think                       16\n",
      "one                         16\n",
      "it.                         15\n",
      "2010,                       14\n",
      "want                        13\n",
      "getting                     12\n",
      "time                        12\n",
      ">\"                          12\n",
      "also                        12\n",
      "speech                      11\n",
      "working                     11\n",
      "could                       11\n",
      "sent                        10\n",
      "see                         10\n",
      "pm,                         10 \n",
      "\n",
      "\n",
      "Community number: 12 \n",
      "\n",
      "               Number of appearances\n",
      "shift                            11\n",
      "work                             10\n",
      "sleep                            10\n",
      "day                               9\n",
      "lgf                               7\n",
      "convoy                            6\n",
      "night                             6\n",
      "average                           5\n",
      "hours                             5\n",
      "days                              5\n",
      "time                              4\n",
      "deprivation.                      4\n",
      "sleeping                          4\n",
      "hour                              4\n",
      "14                                3\n",
      "3                                 3\n",
      "followed                          3\n",
      "shift,                            3\n",
      "transition                        3\n",
      "back                              3 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for commu in range(0,max(edges_community['Community_number']) + 1):\n",
    "    emails_body_clean = edges_community[edges_community['Community_number'] == commu]['ExtractedBodyText']\n",
    "    wordcount_clean = removeStopwords(countWords(emails_body_clean))\n",
    "    wordcount_series = pd.Series(wordcount_clean)\n",
    "    wordcount_sorted = wordcount_series.sort_values(ascending=False).to_frame()\n",
    "    wordcount_sorted.columns = ['Number of appearances']\n",
    "    if not wordcount_sorted.empty:\n",
    "        print(\"Community number:\", commu, \"\\n\\n\", wordcount_sorted.head(20), \"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
